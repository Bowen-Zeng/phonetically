{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 46, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/10099/OneDrive/Documents/phonetically/app/api/speak/route.ts"],"sourcesContent":["/**\r\n * API route for Phona text-to-speech\r\n * Keeps ELEVENLABS_API_KEY and ELEVENLABS_VOICE_ID server-side (not exposed to client)\r\n *\r\n * Env vars: Add to .env.local:\r\n *   ELEVENLABS_API_KEY=your_api_key\r\n *   ELEVENLABS_VOICE_ID=your_phona_voice_id (e.g. EXAVITQu4vr4xnSDxMaL)\r\n */\r\nimport { NextRequest, NextResponse } from 'next/server';\r\n\r\nexport async function POST(request: NextRequest) {\r\n  try {\r\n    const { text } = await request.json();\r\n    if (!text || typeof text !== 'string') {\r\n      return NextResponse.json(\r\n        { error: 'Missing or invalid text' },\r\n        { status: 400 }\r\n      );\r\n    }\r\n\r\n    // INSERT YOUR API KEY via env: ELEVENLABS_API_KEY\r\n    const apiKey = process.env.ELEVENLABS_API_KEY;\r\n    // INSERT YOUR PHONA VOICE ID via env: ELEVENLABS_VOICE_ID\r\n    const voiceId = process.env.ELEVENLABS_VOICE_ID || 'EXAVITQu4vr4xnSDxMaL';\r\n\r\n    if (!apiKey) {\r\n      return NextResponse.json(\r\n        { error: 'ELEVENLABS_API_KEY not configured' },\r\n        { status: 500 }\r\n      );\r\n    }\r\n\r\n    const response = await fetch(\r\n      `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`,\r\n      {\r\n        method: 'POST',\r\n        headers: {\r\n          Accept: 'audio/mpeg',\r\n          'Content-Type': 'application/json',\r\n          'xi-api-key': apiKey,\r\n        },\r\n        body: JSON.stringify({\r\n          text: text.trim(),\r\n          model_id: 'eleven_monolingual_v1',\r\n          voice_settings: { stability: 0.5, similarity_boost: 0.75 },\r\n        }),\r\n      }\r\n    );\r\n\r\n    if (!response.ok) {\r\n      const err = await response.text();\r\n      return NextResponse.json(\r\n        { error: 'ElevenLabs API error', details: err },\r\n        { status: response.status }\r\n      );\r\n    }\r\n\r\n    const audioBuffer = await response.arrayBuffer();\r\n    return new NextResponse(audioBuffer, {\r\n      headers: { 'Content-Type': 'audio/mpeg' },\r\n    });\r\n  } catch (e) {\r\n    console.error('Speak API error:', e);\r\n    return NextResponse.json(\r\n      { error: 'Internal server error' },\r\n      { status: 500 }\r\n    );\r\n  }\r\n}\r\n"],"names":[],"mappings":";;;;AAAA;;;;;;;CAOC,GACD;;AAEO,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,MAAM,EAAE,IAAI,EAAE,GAAG,MAAM,QAAQ,IAAI;QACnC,IAAI,CAAC,QAAQ,OAAO,SAAS,UAAU;YACrC,OAAO,yLAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAA0B,GACnC;gBAAE,QAAQ;YAAI;QAElB;QAEA,kDAAkD;QAClD,MAAM,SAAS,QAAQ,GAAG,CAAC,kBAAkB;QAC7C,0DAA0D;QAC1D,MAAM,UAAU,QAAQ,GAAG,CAAC,mBAAmB,IAAI;QAEnD,IAAI,CAAC,QAAQ;YACX,OAAO,yLAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAAoC,GAC7C;gBAAE,QAAQ;YAAI;QAElB;QAEA,MAAM,WAAW,MAAM,MACrB,CAAC,4CAA4C,EAAE,SAAS,EACxD;YACE,QAAQ;YACR,SAAS;gBACP,QAAQ;gBACR,gBAAgB;gBAChB,cAAc;YAChB;YACA,MAAM,KAAK,SAAS,CAAC;gBACnB,MAAM,KAAK,IAAI;gBACf,UAAU;gBACV,gBAAgB;oBAAE,WAAW;oBAAK,kBAAkB;gBAAK;YAC3D;QACF;QAGF,IAAI,CAAC,SAAS,EAAE,EAAE;YAChB,MAAM,MAAM,MAAM,SAAS,IAAI;YAC/B,OAAO,yLAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;gBAAwB,SAAS;YAAI,GAC9C;gBAAE,QAAQ,SAAS,MAAM;YAAC;QAE9B;QAEA,MAAM,cAAc,MAAM,SAAS,WAAW;QAC9C,OAAO,IAAI,yLAAY,CAAC,aAAa;YACnC,SAAS;gBAAE,gBAAgB;YAAa;QAC1C;IACF,EAAE,OAAO,GAAG;QACV,QAAQ,KAAK,CAAC,oBAAoB;QAClC,OAAO,yLAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAAwB,GACjC;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}